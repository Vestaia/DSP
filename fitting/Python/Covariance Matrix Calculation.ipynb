{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to calculate the covariance matrix of our background data.\n",
    "\n",
    "\n",
    "\n",
    "Fun fact: our covariance array is a Toeplitz matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.linalg\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_time_series = torch.from_numpy(np.loadtxt(\"./data/background_0.dat\", dtype=np.float32))\n",
    "full_time_series = full_time_series.to(device)\n",
    "\n",
    "time_series = full_time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda not supported or something like that\n",
      "Current GPU MB allocated: 0.0\n",
      "Max GPU MB allocated: 0.0\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "except:\n",
    "    print(\"Cuda not supported or something like that\")\n",
    "\n",
    "cov_mat_row_one = []\n",
    "means = []\n",
    "\n",
    "sliding_window_size = 1000\n",
    "batch_size = 100 # experimental so it runs well, must divide sliding_window_size evenly\n",
    "\n",
    "y0_samples = time_series.unfold(0, sliding_window_size, 1).T[0]\n",
    "y0_diff = y0_samples - torch.mean(y0_samples)\n",
    "\n",
    "for i in range(int(sliding_window_size / batch_size)):\n",
    "    samples = time_series.unfold(0, sliding_window_size, 1).T[i * batch_size:(i + 1) * batch_size]\n",
    "    mean = torch.mean(samples, dim=1)\n",
    "    diff = (samples.T - mean).T\n",
    "    cov_mat_row_one.append(diff @ y0_diff / y0_samples.shape[0])\n",
    "    means.append(mean)\n",
    "    del samples\n",
    "    del mean\n",
    "    del diff\n",
    "\n",
    "# clear memory\n",
    "with torch.no_grad(): # not sure if this line is correct\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "cov_mat_row_one = torch.flatten(torch.stack(cov_mat_row_one))\n",
    "means = torch.flatten(torch.stack(means))\n",
    "\n",
    "print(\"Current GPU MB allocated: \" + str(torch.cuda.memory_allocated() / 1024 / 1024))\n",
    "print(\"Max GPU MB allocated: \" + str(torch.cuda.max_memory_allocated() / 1024 / 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda not supported or something like that\n",
      "Current GPU MB allocated: 0.0\n",
      "Max GPU MB allocated: 0.0\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "except:\n",
    "    print(\"Cuda not supported or something like that\")\n",
    "\n",
    "cov_mat = torch.Tensor(scipy.linalg.toeplitz(cov_mat_row_one.cpu().numpy())).to(device)\n",
    "inv_cov_mat = torch.inverse(cov_mat)\n",
    "\n",
    "print(\"Current GPU MB allocated: \" + str(torch.cuda.memory_allocated() / 1024 / 1024))\n",
    "print(\"Max GPU MB allocated: \" + str(torch.cuda.max_memory_allocated() / 1024 / 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(cov_mat, \"saved_tensors/cov_mat_background_0_1000.pt\")\n",
    "torch.save(inv_cov_mat,\"saved_tensors/inv_cov_mat_background_0_1000.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
