{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to calculate the covariance matrix of our background data.\n",
    "\n",
    "\n",
    "\n",
    "Fun fact: our covariance array is a Toeplitz matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.linalg\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_time_series = torch.from_numpy(np.loadtxt(\"./data/background_0.dat\", dtype=np.float32))\n",
    "full_time_series = full_time_series.to(device)\n",
    "\n",
    "time_series = full_time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current MB allocated: 0.0\n",
      "Max MB allocated: 0.0\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "cov_mat_row_one = []\n",
    "\n",
    "sliding_window_size = 1000\n",
    "batch_size = 100 # experimental so it runs well, must divide sliding_window_size evenly\n",
    "\n",
    "y0_samples = time_series.unfold(0, sliding_window_size, 1).T[0]\n",
    "y0_diff = y0_samples - torch.mean(y0_samples)\n",
    "\n",
    "for i in range(int(sliding_window_size / batch_size)):\n",
    "    samples = time_series.unfold(0, sliding_window_size, 1).T[i * batch_size:(i + 1) * batch_size]\n",
    "    mean = torch.mean(samples)\n",
    "    diff = samples - mean\n",
    "    cov_mat_row_one.append(diff @ y0_diff / y0_samples.shape[0])\n",
    "    del samples\n",
    "    del mean\n",
    "    del diff\n",
    "\n",
    "# clear memory\n",
    "with torch.no_grad(): # not sure if this line is correct\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "cov_mat_row_one = torch.flatten(torch.stack(cov_mat_row_one))\n",
    "\n",
    "print(\"Current MB allocated: \" + str(torch.cuda.memory_allocated() / 1024 / 1024))\n",
    "print(\"Max MB allocated: \" + str(torch.cuda.max_memory_allocated() / 1024 / 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current MB allocated: 0.0\n",
      "Max MB allocated: 0.0\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "cov_mat = torch.Tensor(scipy.linalg.toeplitz(cov_mat_row_one.cpu().numpy())).to(device)\n",
    "inv_cov_mat = torch.inverse(cov_mat)\n",
    "\n",
    "print(\"Current MB allocated: \" + str(torch.cuda.memory_allocated() / 1024 / 1024))\n",
    "print(\"Max MB allocated: \" + str(torch.cuda.max_memory_allocated() / 1024 / 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[21.2269,  0.2052,  0.5548,  ...,  0.1212,  0.1267,  0.1557],\n",
      "        [ 0.2052, 21.2269,  0.2052,  ...,  0.1578,  0.1212,  0.1267],\n",
      "        [ 0.5548,  0.2052, 21.2269,  ...,  0.1500,  0.1578,  0.1212],\n",
      "        ...,\n",
      "        [ 0.1212,  0.1578,  0.1500,  ..., 21.2269,  0.2052,  0.5548],\n",
      "        [ 0.1267,  0.1212,  0.1578,  ...,  0.2052, 21.2269,  0.2052],\n",
      "        [ 0.1557,  0.1267,  0.1212,  ...,  0.5548,  0.2052, 21.2269]])\n",
      "tensor([[ 4.7925e-02,  3.0581e-04, -4.9541e-04,  ...,  2.7534e-05,\n",
      "          1.4265e-05, -5.8326e-05],\n",
      "        [ 3.0581e-04,  4.7927e-02,  3.0266e-04,  ..., -5.4640e-05,\n",
      "          2.7022e-05,  1.4265e-05],\n",
      "        [-4.9541e-04,  3.0266e-04,  4.7932e-02,  ..., -4.2612e-05,\n",
      "         -5.4640e-05,  2.7534e-05],\n",
      "        ...,\n",
      "        [ 2.7534e-05, -5.4640e-05, -4.2612e-05,  ...,  4.7932e-02,\n",
      "          3.0266e-04, -4.9541e-04],\n",
      "        [ 1.4265e-05,  2.7022e-05, -5.4640e-05,  ...,  3.0266e-04,\n",
      "          4.7927e-02,  3.0581e-04],\n",
      "        [-5.8327e-05,  1.4265e-05,  2.7534e-05,  ..., -4.9541e-04,\n",
      "          3.0581e-04,  4.7925e-02]])\n",
      "tensor([[ 1.0000e+00,  5.6880e-09,  5.6532e-09,  ..., -4.6566e-10,\n",
      "          1.1642e-09,  6.9849e-10],\n",
      "        [-7.9708e-09,  1.0000e+00, -7.3192e-10,  ...,  0.0000e+00,\n",
      "          2.0955e-09, -1.1642e-09],\n",
      "        [-6.8321e-09, -8.2673e-10,  1.0000e+00,  ...,  9.3132e-10,\n",
      "         -3.2596e-09,  1.6298e-09],\n",
      "        ...,\n",
      "        [-3.8608e-09,  2.6939e-09,  6.8495e-09,  ...,  1.0000e+00,\n",
      "          4.6566e-10, -5.5879e-09],\n",
      "        [-3.6289e-10, -1.2706e-09,  1.9354e-09,  ...,  9.3132e-10,\n",
      "          1.0000e+00, -1.8626e-09],\n",
      "        [-5.5879e-09, -2.0955e-09, -2.0955e-09,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  1.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "print(cov_mat)\n",
    "print(inv_cov_mat)\n",
    "print(cov_mat @ inv_cov_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
